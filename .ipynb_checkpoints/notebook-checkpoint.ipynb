{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link './filelists/CUB/images/images': Read-only file system\n",
      "ln: failed to create symbolic link './filelists/miniImagenet/images/images': Read-only file system\n",
      "ln: failed to create symbolic link './filelists/tieredImagenet/images/tiered_imagenet': Read-only file system\n",
      "ln: failed to create symbolic link './filelists/dogs/images/Images': Read-only file system\n",
      "ln: failed to create symbolic link './filelists/aircrafts/images/images': Read-only file system\n"
     ]
    }
   ],
   "source": [
    "!ln -s /kaggle/input/caltech-birds-2011-dataset/CUB_200_2011/images ./filelists/CUB/images\n",
    "!ln -s /kaggle/input/miniimagenet/miniImageNet/images ./filelists/miniImagenet/images\n",
    "!ln -s /kaggle/input/d/arjun2000ashok/tieredimagenet/tiered_imagenet/ ./filelists/tieredImagenet/images\n",
    "!ln -s /kaggle/input/stanford-dogs-dataset/images/Images ./filelists/dogs/Images\n",
    "!ln -s /kaggle/input/stanford-cars-dataset/cars_train/cars_train ./filelists/cars/images \n",
    "!ln -s /kaggle/input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images ./filelists/aircrafts/images\n",
    "!ln -s /kaggle/input/vggflowers/images ./filelists/flowers/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: ckpts/dogs/_resnet18_protonet_aug_5way_5shot_16query_lr0.0010\n",
      "Resuming from wandb ID:  11vqc3r9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id 11vqc3r9 but id 11vqc3r9 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210529_072837-11vqc3r9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33mdry-frost-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meta-learners/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meta-learners/fsl_ssl/runs/11vqc3r9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26001 < 29024; dropping {'train/loss': 0.5334404706954956}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26002 < 29024; dropping {'train/loss': 0.4051235616207123}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26003 < 29024; dropping {'train/loss': 0.417832612991333}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26004 < 29024; dropping {'train/loss': 0.37183427810668945}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26005 < 29024; dropping {'train/loss': 0.4160655438899994}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26006 < 29024; dropping {'train/loss': 0.2431834489107132}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26007 < 29024; dropping {'train/loss': 0.3473961651325226}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26008 < 29024; dropping {'train/loss': 0.23503167927265167}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26009 < 29024; dropping {'train/loss': 0.34083691239356995}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26010 < 29024; dropping {'train/loss': 0.5087172985076904}.\n",
      "Epoch 260 | Batch 10/100 | Loss 0.381946\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26011 < 29024; dropping {'train/loss': 0.6639684438705444}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26012 < 29024; dropping {'train/loss': 0.24973466992378235}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26013 < 29024; dropping {'train/loss': 0.37760886549949646}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26014 < 29024; dropping {'train/loss': 0.48374319076538086}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26015 < 29024; dropping {'train/loss': 0.4604216516017914}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26016 < 29024; dropping {'train/loss': 0.30958086252212524}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26017 < 29024; dropping {'train/loss': 0.10722191631793976}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26018 < 29024; dropping {'train/loss': 0.25328347086906433}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26019 < 29024; dropping {'train/loss': 0.5172199606895447}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26020 < 29024; dropping {'train/loss': 0.30106493830680847}.\n",
      "Epoch 260 | Batch 20/100 | Loss 0.377165\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26021 < 29024; dropping {'train/loss': 0.41683268547058105}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26022 < 29024; dropping {'train/loss': 0.6110031008720398}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26023 < 29024; dropping {'train/loss': 0.2833022475242615}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26024 < 29024; dropping {'train/loss': 0.24109454452991486}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26025 < 29024; dropping {'train/loss': 0.5692940354347229}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26026 < 29024; dropping {'train/loss': 0.5054501891136169}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26027 < 29024; dropping {'train/loss': 0.48388952016830444}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26028 < 29024; dropping {'train/loss': 0.1971723437309265}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26029 < 29024; dropping {'train/loss': 0.6273892521858215}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26030 < 29024; dropping {'train/loss': 0.3748062252998352}.\n",
      "Epoch 260 | Batch 30/100 | Loss 0.395118\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26031 < 29024; dropping {'train/loss': 0.7338029146194458}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26032 < 29024; dropping {'train/loss': 0.44871410727500916}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26033 < 29024; dropping {'train/loss': 0.42654967308044434}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26034 < 29024; dropping {'train/loss': 0.35770756006240845}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26035 < 29024; dropping {'train/loss': 0.8441664576530457}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26036 < 29024; dropping {'train/loss': 0.3099921643733978}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26037 < 29024; dropping {'train/loss': 0.32269102334976196}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26038 < 29024; dropping {'train/loss': 0.3503918945789337}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26039 < 29024; dropping {'train/loss': 0.5163642168045044}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26040 < 29024; dropping {'train/loss': 0.4192410111427307}.\n",
      "Epoch 260 | Batch 40/100 | Loss 0.414579\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26041 < 29024; dropping {'train/loss': 0.4151436388492584}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26042 < 29024; dropping {'train/loss': 0.5005406141281128}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26043 < 29024; dropping {'train/loss': 0.22692498564720154}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26044 < 29024; dropping {'train/loss': 0.34943774342536926}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26045 < 29024; dropping {'train/loss': 0.24217119812965393}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26046 < 29024; dropping {'train/loss': 0.4798312187194824}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26047 < 29024; dropping {'train/loss': 0.2303611785173416}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26048 < 29024; dropping {'train/loss': 0.4458491802215576}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26049 < 29024; dropping {'train/loss': 0.5044786334037781}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26050 < 29024; dropping {'train/loss': 0.6646875739097595}.\n",
      "Epoch 260 | Batch 50/100 | Loss 0.412852\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26051 < 29024; dropping {'train/loss': 0.6510679125785828}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26052 < 29024; dropping {'train/loss': 0.37635210156440735}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26053 < 29024; dropping {'train/loss': 0.5142530798912048}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26054 < 29024; dropping {'train/loss': 0.4066367745399475}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26055 < 29024; dropping {'train/loss': 0.40958061814308167}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26056 < 29024; dropping {'train/loss': 0.2934219241142273}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26057 < 29024; dropping {'train/loss': 0.2761598229408264}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26058 < 29024; dropping {'train/loss': 0.5104753971099854}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26059 < 29024; dropping {'train/loss': 0.5279830694198608}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26060 < 29024; dropping {'train/loss': 0.24885304272174835}.\n",
      "Epoch 260 | Batch 60/100 | Loss 0.414290\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26061 < 29024; dropping {'train/loss': 0.5722009539604187}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26062 < 29024; dropping {'train/loss': 0.5377805233001709}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26063 < 29024; dropping {'train/loss': 0.2108794003725052}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26064 < 29024; dropping {'train/loss': 0.2855522036552429}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26065 < 29024; dropping {'train/loss': 0.3123754858970642}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26066 < 29024; dropping {'train/loss': 0.5324501395225525}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26067 < 29024; dropping {'train/loss': 0.30446693301200867}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26068 < 29024; dropping {'train/loss': 0.4178318381309509}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26069 < 29024; dropping {'train/loss': 0.29223448038101196}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26070 < 29024; dropping {'train/loss': 0.5959807634353638}.\n",
      "Epoch 260 | Batch 70/100 | Loss 0.413130\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26071 < 29024; dropping {'train/loss': 0.30376872420310974}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26072 < 29024; dropping {'train/loss': 0.21722984313964844}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26073 < 29024; dropping {'train/loss': 0.37387681007385254}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26074 < 29024; dropping {'train/loss': 0.3747454285621643}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26075 < 29024; dropping {'train/loss': 0.3320273160934448}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26076 < 29024; dropping {'train/loss': 0.48147016763687134}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26077 < 29024; dropping {'train/loss': 0.5066107511520386}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26078 < 29024; dropping {'train/loss': 0.40868115425109863}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26079 < 29024; dropping {'train/loss': 0.5492923855781555}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26080 < 29024; dropping {'train/loss': 0.47092145681381226}.\n",
      "Epoch 260 | Batch 80/100 | Loss 0.411722\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26081 < 29024; dropping {'train/loss': 0.3257492482662201}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26082 < 29024; dropping {'train/loss': 0.2584547698497772}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26083 < 29024; dropping {'train/loss': 0.638405442237854}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26084 < 29024; dropping {'train/loss': 0.41413813829421997}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26085 < 29024; dropping {'train/loss': 0.24305549263954163}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26086 < 29024; dropping {'train/loss': 0.37838077545166016}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26087 < 29024; dropping {'train/loss': 0.6205263137817383}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26088 < 29024; dropping {'train/loss': 0.33507731556892395}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26089 < 29024; dropping {'train/loss': 0.3851568102836609}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26090 < 29024; dropping {'train/loss': 0.2886284589767456}.\n",
      "Epoch 260 | Batch 90/100 | Loss 0.409170\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26091 < 29024; dropping {'train/loss': 0.3348758816719055}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26092 < 29024; dropping {'train/loss': 0.38618341088294983}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26093 < 29024; dropping {'train/loss': 0.29578274488449097}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26094 < 29024; dropping {'train/loss': 0.1825558841228485}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26095 < 29024; dropping {'train/loss': 0.4272770881652832}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26096 < 29024; dropping {'train/loss': 0.4049701690673828}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26097 < 29024; dropping {'train/loss': 0.5550509691238403}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26098 < 29024; dropping {'train/loss': 0.382846474647522}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26099 < 29024; dropping {'train/loss': 0.5508803725242615}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26100 < 29024; dropping {'train/loss': 0.3540481626987457}.\n",
      "Epoch 260 | Batch 100/100 | Loss 0.406998\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26101 < 29024; dropping {'train/loss': 0.35189390182495117}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26102 < 29024; dropping {'train/loss': 0.18356624245643616}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26103 < 29024; dropping {'train/loss': 0.37053579092025757}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26104 < 29024; dropping {'train/loss': 0.3930790424346924}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26105 < 29024; dropping {'train/loss': 0.4730769991874695}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26106 < 29024; dropping {'train/loss': 0.4115855097770691}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26107 < 29024; dropping {'train/loss': 0.4068545401096344}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26108 < 29024; dropping {'train/loss': 0.4082789421081543}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26109 < 29024; dropping {'train/loss': 0.2437479943037033}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26110 < 29024; dropping {'train/loss': 0.467939555644989}.\n",
      "Epoch 261 | Batch 10/100 | Loss 0.371056\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26111 < 29024; dropping {'train/loss': 0.5080216526985168}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26112 < 29024; dropping {'train/loss': 0.5171293020248413}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26113 < 29024; dropping {'train/loss': 0.35608142614364624}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26114 < 29024; dropping {'train/loss': 0.2820209562778473}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26115 < 29024; dropping {'train/loss': 0.42552536725997925}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26116 < 29024; dropping {'train/loss': 0.20802263915538788}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26117 < 29024; dropping {'train/loss': 0.3223350942134857}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26118 < 29024; dropping {'train/loss': 0.18366070091724396}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26119 < 29024; dropping {'train/loss': 0.25670430064201355}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26120 < 29024; dropping {'train/loss': 0.3484695255756378}.\n",
      "Epoch 261 | Batch 20/100 | Loss 0.355926\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26121 < 29024; dropping {'train/loss': 0.44063490629196167}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26122 < 29024; dropping {'train/loss': 0.3485073149204254}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26123 < 29024; dropping {'train/loss': 0.5420897006988525}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26124 < 29024; dropping {'train/loss': 0.4180595874786377}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26125 < 29024; dropping {'train/loss': 0.5213432908058167}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26126 < 29024; dropping {'train/loss': 0.26826292276382446}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26127 < 29024; dropping {'train/loss': 0.33189573884010315}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26128 < 29024; dropping {'train/loss': 0.4113098978996277}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26129 < 29024; dropping {'train/loss': 0.833846926689148}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26130 < 29024; dropping {'train/loss': 0.33510690927505493}.\n",
      "Epoch 261 | Batch 30/100 | Loss 0.385653\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26131 < 29024; dropping {'train/loss': 0.4196518361568451}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26132 < 29024; dropping {'train/loss': 0.3990684747695923}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26133 < 29024; dropping {'train/loss': 0.2932950258255005}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26134 < 29024; dropping {'train/loss': 0.3574565052986145}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26135 < 29024; dropping {'train/loss': 0.2276730239391327}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26136 < 29024; dropping {'train/loss': 0.49798113107681274}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26137 < 29024; dropping {'train/loss': 0.6207406520843506}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26138 < 29024; dropping {'train/loss': 0.3440348207950592}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26139 < 29024; dropping {'train/loss': 0.5637441277503967}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26140 < 29024; dropping {'train/loss': 0.4595237374305725}.\n",
      "Epoch 261 | Batch 40/100 | Loss 0.393819\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26141 < 29024; dropping {'train/loss': 0.4034031927585602}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26142 < 29024; dropping {'train/loss': 0.28533902764320374}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26143 < 29024; dropping {'train/loss': 0.16674160957336426}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26144 < 29024; dropping {'train/loss': 0.5913161039352417}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26145 < 29024; dropping {'train/loss': 0.42850035429000854}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26146 < 29024; dropping {'train/loss': 0.38797903060913086}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26147 < 29024; dropping {'train/loss': 0.5197745561599731}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26148 < 29024; dropping {'train/loss': 0.4861488342285156}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26149 < 29024; dropping {'train/loss': 0.3632057011127472}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26150 < 29024; dropping {'train/loss': 0.16678382456302643}.\n",
      "Epoch 261 | Batch 50/100 | Loss 0.391039\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26151 < 29024; dropping {'train/loss': 0.40745335817337036}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26152 < 29024; dropping {'train/loss': 0.6313823461532593}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26153 < 29024; dropping {'train/loss': 0.3605467677116394}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26154 < 29024; dropping {'train/loss': 0.2381150722503662}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26155 < 29024; dropping {'train/loss': 0.4345305562019348}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26156 < 29024; dropping {'train/loss': 0.591437578201294}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26157 < 29024; dropping {'train/loss': 0.34427767992019653}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26158 < 29024; dropping {'train/loss': 0.5662093758583069}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26159 < 29024; dropping {'train/loss': 0.2546355724334717}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26160 < 29024; dropping {'train/loss': 0.40768927335739136}.\n",
      "Epoch 261 | Batch 60/100 | Loss 0.396470\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26161 < 29024; dropping {'train/loss': 0.3831534683704376}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26162 < 29024; dropping {'train/loss': 0.3009566068649292}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26163 < 29024; dropping {'train/loss': 0.5785748958587646}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26164 < 29024; dropping {'train/loss': 0.3446885347366333}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26165 < 29024; dropping {'train/loss': 0.26933300495147705}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26166 < 29024; dropping {'train/loss': 0.43949753046035767}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26167 < 29024; dropping {'train/loss': 0.3358091413974762}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26168 < 29024; dropping {'train/loss': 0.3930298089981079}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26169 < 29024; dropping {'train/loss': 0.5195729732513428}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26170 < 29024; dropping {'train/loss': 0.5609859228134155}.\n",
      "Epoch 261 | Batch 70/100 | Loss 0.398769\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26171 < 29024; dropping {'train/loss': 0.18658187985420227}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26172 < 29024; dropping {'train/loss': 0.36194509267807007}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26173 < 29024; dropping {'train/loss': 0.718587338924408}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26174 < 29024; dropping {'train/loss': 0.20306149125099182}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26175 < 29024; dropping {'train/loss': 0.625893235206604}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26176 < 29024; dropping {'train/loss': 0.31663233041763306}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26177 < 29024; dropping {'train/loss': 0.1962985098361969}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26178 < 29024; dropping {'train/loss': 0.3924328684806824}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26179 < 29024; dropping {'train/loss': 0.23172898590564728}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26180 < 29024; dropping {'train/loss': 0.43501192331314087}.\n",
      "Epoch 261 | Batch 80/100 | Loss 0.394775\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26181 < 29024; dropping {'train/loss': 0.333296537399292}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26182 < 29024; dropping {'train/loss': 0.4423268735408783}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26183 < 29024; dropping {'train/loss': 0.3097066879272461}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26184 < 29024; dropping {'train/loss': 0.5083313584327698}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26185 < 29024; dropping {'train/loss': 0.4833286702632904}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26186 < 29024; dropping {'train/loss': 0.06566323339939117}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26187 < 29024; dropping {'train/loss': 0.4334676265716553}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26188 < 29024; dropping {'train/loss': 0.31556859612464905}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26189 < 29024; dropping {'train/loss': 0.29472118616104126}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26190 < 29024; dropping {'train/loss': 0.8111968040466309}.\n",
      "Epoch 261 | Batch 90/100 | Loss 0.395329\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26191 < 29024; dropping {'train/loss': 0.34808430075645447}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26192 < 29024; dropping {'train/loss': 0.724323034286499}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26193 < 29024; dropping {'train/loss': 0.371804416179657}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26194 < 29024; dropping {'train/loss': 0.27963289618492126}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26195 < 29024; dropping {'train/loss': 0.4559177756309509}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26196 < 29024; dropping {'train/loss': 0.4510177969932556}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26197 < 29024; dropping {'train/loss': 0.4019877016544342}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26198 < 29024; dropping {'train/loss': 0.5073394775390625}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26199 < 29024; dropping {'train/loss': 0.4610827565193176}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26200 < 29024; dropping {'train/loss': 0.5393938422203064}.\n",
      "Epoch 261 | Batch 100/100 | Loss 0.401202\n",
      "100 Test Protonet Acc = 80.10% +- 1.40%\n",
      "best model! save...\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26201 < 29024; dropping {'train/loss': 0.4276370406150818}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26202 < 29024; dropping {'train/loss': 0.2242966890335083}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26203 < 29024; dropping {'train/loss': 0.331625759601593}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26204 < 29024; dropping {'train/loss': 0.31181806325912476}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26205 < 29024; dropping {'train/loss': 0.5548087954521179}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26206 < 29024; dropping {'train/loss': 0.44544535875320435}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26207 < 29024; dropping {'train/loss': 0.40515390038490295}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26208 < 29024; dropping {'train/loss': 0.5378249287605286}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26209 < 29024; dropping {'train/loss': 0.2681768536567688}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26210 < 29024; dropping {'train/loss': 0.5339999794960022}.\n",
      "Epoch 262 | Batch 10/100 | Loss 0.404079\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26211 < 29024; dropping {'train/loss': 0.2587333917617798}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26212 < 29024; dropping {'train/loss': 0.4958342909812927}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26213 < 29024; dropping {'train/loss': 0.2931618392467499}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26214 < 29024; dropping {'train/loss': 0.19737140834331512}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26215 < 29024; dropping {'train/loss': 0.3605163097381592}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26216 < 29024; dropping {'train/loss': 0.6749565005302429}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26217 < 29024; dropping {'train/loss': 0.39393219351768494}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26218 < 29024; dropping {'train/loss': 0.3571619391441345}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26219 < 29024; dropping {'train/loss': 0.18793989717960358}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26220 < 29024; dropping {'train/loss': 0.49310413002967834}.\n",
      "Epoch 262 | Batch 20/100 | Loss 0.387675\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26221 < 29024; dropping {'train/loss': 0.3012915849685669}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26222 < 29024; dropping {'train/loss': 0.1523473560810089}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26223 < 29024; dropping {'train/loss': 0.21767310798168182}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26224 < 29024; dropping {'train/loss': 0.2787773907184601}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26225 < 29024; dropping {'train/loss': 0.34265902638435364}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26226 < 29024; dropping {'train/loss': 0.18211881816387177}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26227 < 29024; dropping {'train/loss': 0.2672639787197113}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26228 < 29024; dropping {'train/loss': 0.15527236461639404}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26229 < 29024; dropping {'train/loss': 0.3888484835624695}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26230 < 29024; dropping {'train/loss': 0.2547655701637268}.\n",
      "Epoch 262 | Batch 30/100 | Loss 0.343151\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26231 < 29024; dropping {'train/loss': 0.3551894724369049}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26232 < 29024; dropping {'train/loss': 0.24407926201820374}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26233 < 29024; dropping {'train/loss': 0.42707186937332153}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26234 < 29024; dropping {'train/loss': 0.5736474394798279}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26235 < 29024; dropping {'train/loss': 0.4247855544090271}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26236 < 29024; dropping {'train/loss': 0.3742257058620453}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26237 < 29024; dropping {'train/loss': 0.2374478131532669}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26238 < 29024; dropping {'train/loss': 0.36604923009872437}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26239 < 29024; dropping {'train/loss': 0.3099181354045868}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26240 < 29024; dropping {'train/loss': 0.1793297678232193}.\n",
      "Epoch 262 | Batch 40/100 | Loss 0.344657\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26241 < 29024; dropping {'train/loss': 0.5656542778015137}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26242 < 29024; dropping {'train/loss': 0.6753965616226196}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26243 < 29024; dropping {'train/loss': 0.47464531660079956}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26244 < 29024; dropping {'train/loss': 0.39155492186546326}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26245 < 29024; dropping {'train/loss': 0.28563278913497925}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26246 < 29024; dropping {'train/loss': 0.5096100568771362}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26247 < 29024; dropping {'train/loss': 0.630435585975647}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 26248 < 29024; dropping {'train/loss': 0.3761865198612213}.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset dogs --train_aug --resume --resume_wandb_id 11vqc3r9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

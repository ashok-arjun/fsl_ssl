{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./filelists/CUB/\n",
    "# !ln -s  ../../../CUB_200_2011/images ./images\n",
    "# %cd ../../\n",
    "\n",
    "!ln -s /kaggle/input/caltech-birds-2011-dataset/CUB_200_2011/images ./filelists/CUB/images\n",
    "\n",
    "# !ln -s /kaggle/input/miniimagenet/miniImageNet/images ./filelists/miniImagenet/images\n",
    "# !ln -s /kaggle/input/d/arjun2000ashok/tieredimagenet/tiered_imagenet/ ./filelists/tieredImagenet/images\n",
    "# !ln -s /kaggle/input/stanford-dogs-dataset/images/Images ./filelists/dogs/Images\n",
    "# !ln -s /kaggle/input/cars-dataset/images ./filelists/cars/images \n",
    "# !ln -s /kaggle/input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images ./filelists/aircrafts/images\n",
    "# !ln -s /kaggle/input/vggflowers/images ./filelists/flowers/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1 windows (created Sun Jun 13 03:08:54 2021) [137x32] (attached)\n",
      "1: 1 windows (created Sun Jun 13 04:00:24 2021) [80x23]\n"
     ]
    }
   ],
   "source": [
    "!tmux ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: python: command not found\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset cars --train_aug --method protonet --committed --stop_epoch 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210609_045359-vba5sgld\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33maircrafts protonet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl/runs/vba5sgld\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Checkpoint restored at  ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/best_model.tar\n",
      "The model's epoch is  399\n",
      "Please rename it to continue training\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 440\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20210609_045359-vba5sgld/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20210609_045359-vba5sgld/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _step 40000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/acc 90.6625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val/loss_avg 0.2686292827129364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     val/loss_proto 0.2686292827129364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train/acc_proto 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/loss_proto 0.03371390700340271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _runtime 78198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         _timestamp 1623189826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/loss 0.03371390700340271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33maircrafts protonet\u001b[0m: \u001b[34mhttps://wandb.ai/multi-input/fsl_ssl/runs/vba5sgld\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python wandb_restore.py --id vba5sgld --path ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/best_model.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit after saving features and testing.\n",
      "checkpoint_dir: ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010\n",
      "USE BN: True\n",
      "outfile is features/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/novel.hdf5\n",
      "0/40\n",
      "10/40\n",
      "20/40\n",
      "30/40\n"
     ]
    }
   ],
   "source": [
    "# Do again with 200 dimensions\n",
    "# Do again with 399.tar\n",
    "\n",
    "!python save_features.py --dataset aircrafts --train_aug --method protonet --committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing involves fine-tuning. Commit after testing.\n",
      "novel_file features/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/novel.hdf5\n",
      "600 Test Acc = 91.90% +- 0.35%\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataset aircrafts --train_aug --method protonet --committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking in baseline train: True\n",
      "USE pre-trained model: False\n",
      "Checkpoint path: ckpts/aircrafts/_resnet18_baseline_aug_tracking_jigsaw_lbda0.50Adam_lr0.0010\n",
      "Fresh wandb run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210609_053152-2j3ciima\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhonest-plant-71\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl/runs/2j3ciima\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "About to start training. Last model and best model will be saved in wandb at every model save. \n",
      " Run save_features.py and test.py after the training completes, with the same arguments\n",
      "Epoch 1 | Batch 50/313 | Loss 3.908358 | Loss Cls 4.318188 | Loss Jigsaw 3.498529 | Acc Cls 0.017500 | Acc Jigsaw 0.095000\n",
      "Epoch 1 | Batch 100/313 | Loss 3.843621 | Loss Cls 4.165154 | Loss Jigsaw 3.522088 | Acc Cls 0.023750 | Acc Jigsaw 0.083125\n",
      "Epoch 1 | Batch 150/313 | Loss 3.822317 | Loss Cls 4.115179 | Loss Jigsaw 3.529454 | Acc Cls 0.022500 | Acc Jigsaw 0.074167\n",
      "Epoch 1 | Batch 200/313 | Loss 3.808955 | Loss Cls 4.082221 | Loss Jigsaw 3.535689 | Acc Cls 0.024375 | Acc Jigsaw 0.063750\n",
      "Epoch 1 | Batch 250/313 | Loss 3.798203 | Loss Cls 4.057579 | Loss Jigsaw 3.538826 | Acc Cls 0.023750 | Acc Jigsaw 0.054500\n",
      "Epoch 1 | Batch 300/313 | Loss 3.791967 | Loss Cls 4.036258 | Loss Jigsaw 3.547680 | Acc Cls 0.024583 | Acc Jigsaw 0.049375\n",
      "Epoch 2 | Batch 50/313 | Loss 3.731069 | Loss Cls 3.904525 | Loss Jigsaw 3.557613 | Acc Cls 0.032500 | Acc Jigsaw 0.056250\n",
      "Epoch 2 | Batch 100/313 | Loss 3.728743 | Loss Cls 3.902634 | Loss Jigsaw 3.554849 | Acc Cls 0.034375 | Acc Jigsaw 0.050000\n",
      "Epoch 2 | Batch 150/313 | Loss 3.726727 | Loss Cls 3.903623 | Loss Jigsaw 3.549831 | Acc Cls 0.037500 | Acc Jigsaw 0.047083\n",
      "Epoch 2 | Batch 200/313 | Loss 3.720500 | Loss Cls 3.910901 | Loss Jigsaw 3.530097 | Acc Cls 0.035625 | Acc Jigsaw 0.052812\n",
      "Epoch 2 | Batch 250/313 | Loss 3.722607 | Loss Cls 3.914757 | Loss Jigsaw 3.530457 | Acc Cls 0.035500 | Acc Jigsaw 0.049250\n",
      "Epoch 2 | Batch 300/313 | Loss 3.723102 | Loss Cls 3.912611 | Loss Jigsaw 3.533591 | Acc Cls 0.036250 | Acc Jigsaw 0.043958\n",
      "Epoch 3 | Batch 50/313 | Loss 3.682442 | Loss Cls 3.852431 | Loss Jigsaw 3.512453 | Acc Cls 0.042500 | Acc Jigsaw 0.068750\n",
      "Epoch 3 | Batch 100/313 | Loss 3.699393 | Loss Cls 3.866964 | Loss Jigsaw 3.531821 | Acc Cls 0.040000 | Acc Jigsaw 0.071250\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset aircrafts --train_aug --method baseline --jigsaw --lbda 0.5 --committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking in baseline train: True\n",
      "USE pre-trained model: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0cd09855391f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_unused_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, device_ids, output_device, dim, broadcast_buffers, process_group, bucket_cap_mb, find_unused_parameters, check_reduction)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocess_group\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m     \"\"\"\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         raise RuntimeError(\"Default process group has not been initialized, \"\n\u001b[0m\u001b[1;32m    286\u001b[0m                            \"please make sure to call init_process_group.\")\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "from methods.baselinetrain import BaselineTrain\n",
    "from io_utils import model_dict\n",
    "import torch.nn as nn\n",
    "\n",
    "gpu = 0\n",
    "\n",
    "model = BaselineTrain(model_dict[\"resnet18\"], 10)\n",
    "# if more than 1 gpu, syncbatchnorm\n",
    "\n",
    "model = model.cuda(gpu)\n",
    "\n",
    "model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu], find_unused_parameters=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking in baseline train: True\n",
      "USE pre-trained model: False\n",
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_pre_hooks', '_forward_unimplemented', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'buffers', 'children', 'classifier', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'feature', 'float', 'forward', 'forward_loss', 'global_count', 'half', 'jigsaw', 'lbda', 'load_state_dict', 'loss_fn', 'loss_type', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_class', 'parameters', 'pretrain', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'requires_grad_', 'rotation', 'share_memory', 'state_dict', 'test_loop', 'test_loop_with_loss', 'to', 'tracking', 'train', 'train_loop', 'training', 'type', 'zero_grad']\n",
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_pre_hooks', '_forward_unimplemented', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'buffers', 'children', 'cpu', 'cuda', 'device_ids', 'dim', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'gather', 'half', 'load_state_dict', 'module', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'output_device', 'parallel_apply', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'replicate', 'requires_grad_', 'scatter', 'share_memory', 'src_device_obj', 'state_dict', 'to', 'train', 'training', 'type', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "from methods.baselinetrain import BaselineTrain\n",
    "from io_utils import model_dict\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "rank = 0\n",
    "# dist.init_process_group(backend='nccl', init_method='env://', world_size=1, rank=rank)\n",
    "\n",
    "def train(gpu=0):\n",
    "    \n",
    "    \n",
    "    model = BaselineTrain(model_dict[\"resnet18\"], 10)\n",
    "    # if more than 1 gpu, syncbatchnorm here\n",
    "    model = model.cuda(gpu)\n",
    "    print(dir(model))\n",
    "    model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu], find_unused_parameters=True) \n",
    "    print(dir(model))\n",
    "\n",
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '29534'\n",
    "# world_size = 1 * 1\n",
    "# mp.spawn(train, nprocs=1, args=())\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

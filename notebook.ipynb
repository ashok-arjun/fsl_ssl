{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./filelists/CUB/\n",
    "# !ln -s  ../../../CUB_200_2011/images ./images\n",
    "# %cd ../../\n",
    "\n",
    "# !ln -s /kaggle/input/caltech-birds-2011-dataset/CUB_200_2011/images ./filelists/CUB/images\n",
    "\n",
    "# !ln -s /kaggle/input/miniimagenet/miniImageNet/images ./filelists/miniImagenet/images\n",
    "# !ln -s /kaggle/input/d/arjun2000ashok/tieredimagenet/tiered_imagenet/ ./filelists/tieredImagenet/images\n",
    "# !ln -s /kaggle/input/stanford-dogs-dataset/images/Images ./filelists/dogs/Images\n",
    "# !ln -s /kaggle/input/cars-dataset/images ./filelists/cars/images \n",
    "!ln -s /kaggle/input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images ./filelists/aircrafts/images\n",
    "# !ln -s /kaggle/input/vggflowers/images ./filelists/flowers/images\n",
    "\n",
    "# For colab: cd /content & kaggle datasets download -d jutrera/stanford-car-dataset-by-classes-folder & ln -s /content/car_data/car_data/ /content/fsl_ssl/filelists/cars/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/fsl_ssl'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plan : \n",
    "\n",
    "# Put a run\n",
    "# List edits to mkae and tests to perform\n",
    "# Put BG\n",
    "# Make edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: ckpts/cars/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010\n",
      "Fresh wandb run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210608_180130-3ppbzp92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-resonance-66\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl/runs/3ppbzp92\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "About to start training. Last model and best model will be saved in wandb at every model save. \n",
      " Run save_features.py and test.py after the training completes, with the same arguments\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 264, in <module>\n",
      "    train(base_loader, val_loader,  model, start_epoch, stop_epoch, params)\n",
      "  File \"train.py\", line 44, in train\n",
      "    model.train_loop(epoch, base_loader, optimizer, writer) # CHECKED\n",
      "  File \"/kaggle/working/fsl_ssl/methods/protonet.py\", line 110, in train_loop\n",
      "    for i, inputs in enumerate(train_loader):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 363, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 989, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1014, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/_utils.py\", line 395, in reraise\n",
      "    raise self.exc_type(msg)\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/kaggle/working/fsl_ssl/data/dataset.py\", line 147, in __getitem__\n",
      "    return next(iter(self.sub_dataloader[i]))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 363, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 403, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/kaggle/working/fsl_ssl/data/dataset.py\", line 175, in __getitem__\n",
      "    img = Image.open(image_path).convert('RGB')\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/PIL/Image.py\", line 2878, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'filelists/cars/images/train/00979.jpg'\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20210608_180130-3ppbzp92/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20210608_180130-3ppbzp92/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-resonance-66\u001b[0m: \u001b[34mhttps://wandb.ai/multi-input/fsl_ssl/runs/3ppbzp92\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset cars --train_aug --method protonet --committed --stop_epoch 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210609_045359-vba5sgld\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33maircrafts protonet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl/runs/vba5sgld\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Checkpoint restored at  ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/best_model.tar\n",
      "The model's epoch is  399\n",
      "Please rename it to continue training\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 440\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20210609_045359-vba5sgld/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20210609_045359-vba5sgld/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _step 40000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/acc 90.6625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val/loss_avg 0.2686292827129364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     val/loss_proto 0.2686292827129364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train/acc_proto 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/loss_proto 0.03371390700340271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _runtime 78198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         _timestamp 1623189826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/loss 0.03371390700340271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33maircrafts protonet\u001b[0m: \u001b[34mhttps://wandb.ai/multi-input/fsl_ssl/runs/vba5sgld\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python wandb_restore.py --id vba5sgld --path ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/best_model.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit after saving features and testing.\n",
      "checkpoint_dir: ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010\n",
      "USE BN: True\n",
      "outfile is features/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/novel.hdf5\n",
      "0/40\n",
      "10/40\n",
      "20/40\n",
      "30/40\n"
     ]
    }
   ],
   "source": [
    "# Do again with 200 dimensions\n",
    "# Do again with 399.tar\n",
    "\n",
    "!python save_features.py --dataset aircrafts --train_aug --method protonet --committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing involves fine-tuning. Commit after testing.\n",
      "novel_file features/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/novel.hdf5\n",
      "600 Test Acc = 91.90% +- 0.35%\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataset aircrafts --train_aug --method protonet --committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking in baseline train: True\n",
      "USE pre-trained model: False\n",
      "Checkpoint path: ckpts/aircrafts/_resnet18_baseline_aug_tracking_jigsaw_lbda0.50Adam_lr0.0010\n",
      "Fresh wandb run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210609_053152-2j3ciima\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhonest-plant-71\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl/runs/2j3ciima\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "About to start training. Last model and best model will be saved in wandb at every model save. \n",
      " Run save_features.py and test.py after the training completes, with the same arguments\n",
      "Epoch 1 | Batch 50/313 | Loss 3.908358 | Loss Cls 4.318188 | Loss Jigsaw 3.498529 | Acc Cls 0.017500 | Acc Jigsaw 0.095000\n",
      "Epoch 1 | Batch 100/313 | Loss 3.843621 | Loss Cls 4.165154 | Loss Jigsaw 3.522088 | Acc Cls 0.023750 | Acc Jigsaw 0.083125\n",
      "Epoch 1 | Batch 150/313 | Loss 3.822317 | Loss Cls 4.115179 | Loss Jigsaw 3.529454 | Acc Cls 0.022500 | Acc Jigsaw 0.074167\n",
      "Epoch 1 | Batch 200/313 | Loss 3.808955 | Loss Cls 4.082221 | Loss Jigsaw 3.535689 | Acc Cls 0.024375 | Acc Jigsaw 0.063750\n",
      "Epoch 1 | Batch 250/313 | Loss 3.798203 | Loss Cls 4.057579 | Loss Jigsaw 3.538826 | Acc Cls 0.023750 | Acc Jigsaw 0.054500\n",
      "Epoch 1 | Batch 300/313 | Loss 3.791967 | Loss Cls 4.036258 | Loss Jigsaw 3.547680 | Acc Cls 0.024583 | Acc Jigsaw 0.049375\n",
      "Epoch 2 | Batch 50/313 | Loss 3.731069 | Loss Cls 3.904525 | Loss Jigsaw 3.557613 | Acc Cls 0.032500 | Acc Jigsaw 0.056250\n",
      "Epoch 2 | Batch 100/313 | Loss 3.728743 | Loss Cls 3.902634 | Loss Jigsaw 3.554849 | Acc Cls 0.034375 | Acc Jigsaw 0.050000\n",
      "Epoch 2 | Batch 150/313 | Loss 3.726727 | Loss Cls 3.903623 | Loss Jigsaw 3.549831 | Acc Cls 0.037500 | Acc Jigsaw 0.047083\n",
      "Epoch 2 | Batch 200/313 | Loss 3.720500 | Loss Cls 3.910901 | Loss Jigsaw 3.530097 | Acc Cls 0.035625 | Acc Jigsaw 0.052812\n",
      "Epoch 2 | Batch 250/313 | Loss 3.722607 | Loss Cls 3.914757 | Loss Jigsaw 3.530457 | Acc Cls 0.035500 | Acc Jigsaw 0.049250\n",
      "Epoch 2 | Batch 300/313 | Loss 3.723102 | Loss Cls 3.912611 | Loss Jigsaw 3.533591 | Acc Cls 0.036250 | Acc Jigsaw 0.043958\n",
      "Epoch 3 | Batch 50/313 | Loss 3.682442 | Loss Cls 3.852431 | Loss Jigsaw 3.512453 | Acc Cls 0.042500 | Acc Jigsaw 0.068750\n",
      "Epoch 3 | Batch 100/313 | Loss 3.699393 | Loss Cls 3.866964 | Loss Jigsaw 3.531821 | Acc Cls 0.040000 | Acc Jigsaw 0.071250\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset aircrafts --train_aug --method baseline --jigsaw --lbda 0.5 --committed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
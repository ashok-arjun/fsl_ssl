{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./filelists/CUB/\n",
    "# !ln -s  ../../../CUB_200_2011/images ./images\n",
    "# %cd ../../\n",
    "\n",
    "# !ln -s /kaggle/input/caltech-birds-2011-dataset/CUB_200_2011/images ./filelists/CUB/images\n",
    "\n",
    "# !ln -s /kaggle/input/miniimagenet/miniImageNet/images ./filelists/miniImagenet/images\n",
    "# !ln -s /kaggle/input/d/arjun2000ashok/tieredimagenet/tiered_imagenet/ ./filelists/tieredImagenet/images\n",
    "# !ln -s /kaggle/input/stanford-dogs-dataset/images/Images ./filelists/dogs/Images\n",
    "# !ln -s /kaggle/input/stanford-cars-dataset/cars_train/cars_train ./filelists/cars/images \n",
    "# !ln -s /kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data ./filelists/cars/images \n",
    "!ln -s /kaggle/input/fgvc-aircraft/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images ./filelists/aircrafts/images\n",
    "# !ln -s /kaggle/input/vggflowers/images ./filelists/flowers/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210608_105423-38lur2nc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvital-violet-13\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/multi-input/static\" target=\"_blank\">https://wandb.ai/multi-input/static</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/multi-input/static/runs/38lur2nc\" target=\"_blank\">https://wandb.ai/multi-input/static/runs/38lur2nc</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1 < 3; dropping {'metric_2': 4}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 31095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20210608_105423-38lur2nc/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20210608_105423-38lur2nc/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metric_1 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1623149666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metric_1 â–â–…â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _step â–â–…â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mvital-violet-13\u001b[0m: \u001b[34mhttps://wandb.ai/multi-input/static/runs/38lur2nc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"static\")\n",
    "\n",
    "wandb.log({\"metric_1\": 3}, step=1)\n",
    "wandb.log({\"metric_1\": 6}, step=2)\n",
    "wandb.log({\"metric_1\": 9}, step=3)\n",
    "\n",
    "wandb.log({\"metric_2\": 4}, step=1)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/fsl_ssl'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plan : \n",
    "\n",
    "# Put a run\n",
    "# List edits to mkae and tests to perform\n",
    "# Put BG\n",
    "# Make edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010\n",
      "Resuming from wandb ID:  vba5sgld\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id vba5sgld but id vba5sgld is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210608_174219-vba5sgld\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33maircrafts protonet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl/runs/vba5sgld\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "About to start training. Last model and best model will be saved in wandb at every model save. \n",
      " Run save_features.py and test.py after the training completes, with the same arguments\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32001 < 32820; dropping {'train/loss_proto': 0.17186234891414642}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32001 < 32820; dropping {'train/acc_proto': 0.9375}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32001 < 32820; dropping {'train/loss': 0.17186234891414642}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32002 < 32820; dropping {'train/loss_proto': 0.040438681840896606}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32002 < 32820; dropping {'train/acc_proto': 0.9875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32002 < 32820; dropping {'train/loss': 0.040438681840896606}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32003 < 32820; dropping {'train/loss_proto': 0.18945792317390442}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32003 < 32820; dropping {'train/acc_proto': 0.95}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32003 < 32820; dropping {'train/loss': 0.18945792317390442}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32004 < 32820; dropping {'train/loss_proto': 0.03461269289255142}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32004 < 32820; dropping {'train/acc_proto': 0.9875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32004 < 32820; dropping {'train/loss': 0.03461269289255142}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32005 < 32820; dropping {'train/loss_proto': 0.23090270161628723}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32005 < 32820; dropping {'train/acc_proto': 0.9125}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32005 < 32820; dropping {'train/loss': 0.23090270161628723}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32006 < 32820; dropping {'train/loss_proto': 0.05350474640727043}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32006 < 32820; dropping {'train/acc_proto': 0.975}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32006 < 32820; dropping {'train/loss': 0.05350474640727043}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32007 < 32820; dropping {'train/loss_proto': 0.3076298236846924}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32007 < 32820; dropping {'train/acc_proto': 0.925}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32007 < 32820; dropping {'train/loss': 0.3076298236846924}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32008 < 32820; dropping {'train/loss_proto': 0.3697166442871094}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32008 < 32820; dropping {'train/acc_proto': 0.85}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32008 < 32820; dropping {'train/loss': 0.3697166442871094}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32009 < 32820; dropping {'train/loss_proto': 0.11346109956502914}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32009 < 32820; dropping {'train/acc_proto': 0.95}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32009 < 32820; dropping {'train/loss': 0.11346109956502914}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32010 < 32820; dropping {'train/loss_proto': 0.21907398104667664}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32010 < 32820; dropping {'train/acc_proto': 0.9375}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32010 < 32820; dropping {'train/loss': 0.21907398104667664}.\n",
      "Epoch 320 | Batch 10/100 | Loss 0.173066\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32011 < 32820; dropping {'train/loss_proto': 0.08444078266620636}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32011 < 32820; dropping {'train/acc_proto': 0.975}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32011 < 32820; dropping {'train/loss': 0.08444078266620636}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32012 < 32820; dropping {'train/loss_proto': 0.11711907386779785}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32012 < 32820; dropping {'train/acc_proto': 0.9625}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32012 < 32820; dropping {'train/loss': 0.11711907386779785}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32013 < 32820; dropping {'train/loss_proto': 0.3333185613155365}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32013 < 32820; dropping {'train/acc_proto': 0.875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32013 < 32820; dropping {'train/loss': 0.3333185613155365}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32014 < 32820; dropping {'train/loss_proto': 0.04044867306947708}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32014 < 32820; dropping {'train/acc_proto': 0.9875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32014 < 32820; dropping {'train/loss': 0.04044867306947708}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32015 < 32820; dropping {'train/loss_proto': 0.21743445098400116}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32015 < 32820; dropping {'train/acc_proto': 0.9375}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32015 < 32820; dropping {'train/loss': 0.21743445098400116}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32016 < 32820; dropping {'train/loss_proto': 0.015484601259231567}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32016 < 32820; dropping {'train/acc_proto': 1.0}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32016 < 32820; dropping {'train/loss': 0.015484601259231567}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32017 < 32820; dropping {'train/loss_proto': 0.3618921935558319}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32017 < 32820; dropping {'train/acc_proto': 0.8375}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32017 < 32820; dropping {'train/loss': 0.3618921935558319}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32018 < 32820; dropping {'train/loss_proto': 0.12834101915359497}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32018 < 32820; dropping {'train/acc_proto': 0.95}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32018 < 32820; dropping {'train/loss': 0.12834101915359497}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32019 < 32820; dropping {'train/loss_proto': 0.11631007492542267}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32019 < 32820; dropping {'train/acc_proto': 0.9625}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32019 < 32820; dropping {'train/loss': 0.11631007492542267}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32020 < 32820; dropping {'train/loss_proto': 0.08712827414274216}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32020 < 32820; dropping {'train/acc_proto': 0.9875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32020 < 32820; dropping {'train/loss': 0.08712827414274216}.\n",
      "Epoch 320 | Batch 20/100 | Loss 0.161629\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32021 < 32820; dropping {'train/loss_proto': 0.2442932426929474}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32021 < 32820; dropping {'train/acc_proto': 0.8875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32021 < 32820; dropping {'train/loss': 0.2442932426929474}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32022 < 32820; dropping {'train/loss_proto': 0.09582293033599854}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32022 < 32820; dropping {'train/acc_proto': 0.9625}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32022 < 32820; dropping {'train/loss': 0.09582293033599854}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32023 < 32820; dropping {'train/loss_proto': 0.06902618706226349}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32023 < 32820; dropping {'train/acc_proto': 0.9625}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32023 < 32820; dropping {'train/loss': 0.06902618706226349}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32024 < 32820; dropping {'train/loss_proto': 0.10838054120540619}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32024 < 32820; dropping {'train/acc_proto': 0.9625}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32024 < 32820; dropping {'train/loss': 0.10838054120540619}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32025 < 32820; dropping {'train/loss_proto': 0.09934506565332413}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32025 < 32820; dropping {'train/acc_proto': 0.95}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32025 < 32820; dropping {'train/loss': 0.09934506565332413}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32026 < 32820; dropping {'train/loss_proto': 0.1457713544368744}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32026 < 32820; dropping {'train/acc_proto': 0.9625}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32026 < 32820; dropping {'train/loss': 0.1457713544368744}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32027 < 32820; dropping {'train/loss_proto': 0.2930486500263214}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32027 < 32820; dropping {'train/acc_proto': 0.925}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32027 < 32820; dropping {'train/loss': 0.2930486500263214}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32028 < 32820; dropping {'train/loss_proto': 0.1506325900554657}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32028 < 32820; dropping {'train/acc_proto': 0.95}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32028 < 32820; dropping {'train/loss': 0.1506325900554657}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32029 < 32820; dropping {'train/loss_proto': 0.0293797105550766}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32029 < 32820; dropping {'train/acc_proto': 0.9875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32029 < 32820; dropping {'train/loss': 0.0293797105550766}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32030 < 32820; dropping {'train/loss_proto': 0.007971921935677528}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32030 < 32820; dropping {'train/acc_proto': 1.0}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32030 < 32820; dropping {'train/loss': 0.007971921935677528}.\n",
      "Epoch 320 | Batch 30/100 | Loss 0.149208\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32031 < 32820; dropping {'train/loss_proto': 0.13765010237693787}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32031 < 32820; dropping {'train/acc_proto': 0.9375}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32031 < 32820; dropping {'train/loss': 0.13765010237693787}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32032 < 32820; dropping {'train/loss_proto': 0.13485963642597198}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32032 < 32820; dropping {'train/acc_proto': 0.95}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32032 < 32820; dropping {'train/loss': 0.13485963642597198}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32033 < 32820; dropping {'train/loss_proto': 0.07737527787685394}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32033 < 32820; dropping {'train/acc_proto': 0.975}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32033 < 32820; dropping {'train/loss': 0.07737527787685394}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32034 < 32820; dropping {'train/loss_proto': 0.1391657143831253}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32034 < 32820; dropping {'train/acc_proto': 0.9625}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32034 < 32820; dropping {'train/loss': 0.1391657143831253}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32035 < 32820; dropping {'train/loss_proto': 0.13904576003551483}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32035 < 32820; dropping {'train/acc_proto': 0.925}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32035 < 32820; dropping {'train/loss': 0.13904576003551483}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32036 < 32820; dropping {'train/loss_proto': 0.08332480490207672}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32036 < 32820; dropping {'train/acc_proto': 0.975}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32036 < 32820; dropping {'train/loss': 0.08332480490207672}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32037 < 32820; dropping {'train/loss_proto': 0.06202820688486099}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32037 < 32820; dropping {'train/acc_proto': 0.9875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32037 < 32820; dropping {'train/loss': 0.06202820688486099}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32038 < 32820; dropping {'train/loss_proto': 0.22049836814403534}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32038 < 32820; dropping {'train/acc_proto': 0.95}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32038 < 32820; dropping {'train/loss': 0.22049836814403534}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32039 < 32820; dropping {'train/loss_proto': 0.0679507702589035}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32039 < 32820; dropping {'train/acc_proto': 0.9875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32039 < 32820; dropping {'train/loss': 0.0679507702589035}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32040 < 32820; dropping {'train/loss_proto': 0.327403724193573}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32040 < 32820; dropping {'train/acc_proto': 0.875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32040 < 32820; dropping {'train/loss': 0.327403724193573}.\n",
      "Epoch 320 | Batch 40/100 | Loss 0.146639\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32041 < 32820; dropping {'train/loss_proto': 0.23534798622131348}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32041 < 32820; dropping {'train/acc_proto': 0.9}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32041 < 32820; dropping {'train/loss': 0.23534798622131348}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32042 < 32820; dropping {'train/loss_proto': 0.34257394075393677}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32042 < 32820; dropping {'train/acc_proto': 0.9125}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32042 < 32820; dropping {'train/loss': 0.34257394075393677}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32043 < 32820; dropping {'train/loss_proto': 0.0918634682893753}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32043 < 32820; dropping {'train/acc_proto': 0.975}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32043 < 32820; dropping {'train/loss': 0.0918634682893753}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32044 < 32820; dropping {'train/loss_proto': 0.21357080340385437}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32044 < 32820; dropping {'train/acc_proto': 0.8875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32044 < 32820; dropping {'train/loss': 0.21357080340385437}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32045 < 32820; dropping {'train/loss_proto': 0.13043570518493652}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32045 < 32820; dropping {'train/acc_proto': 0.95}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32045 < 32820; dropping {'train/loss': 0.13043570518493652}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32046 < 32820; dropping {'train/loss_proto': 0.04600789397954941}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32046 < 32820; dropping {'train/acc_proto': 0.9875}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32046 < 32820; dropping {'train/loss': 0.04600789397954941}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32047 < 32820; dropping {'train/loss_proto': 0.2434958666563034}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32047 < 32820; dropping {'train/acc_proto': 0.9}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32047 < 32820; dropping {'train/loss': 0.2434958666563034}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32048 < 32820; dropping {'train/loss_proto': 0.02885620668530464}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32048 < 32820; dropping {'train/acc_proto': 1.0}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 32048 < 32820; dropping {'train/loss': 0.02885620668530464}.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset aircrafts --train_aug --method protonet --committed --stop_epoch 400 --resume --resume_wandb_id vba5sgld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210608_170917-vba5sgld\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33maircrafts protonet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/multi-input/fsl_ssl/runs/vba5sgld\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Checkpoint restored at  ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/last_model.tar\n",
      "The model's epoch is  319\n",
      "Please rename it to continue training\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20210608_170917-vba5sgld/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20210608_170917-vba5sgld/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 61529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1623157866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/loss 0.13386337459087372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 32819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val/acc 89.975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33maircrafts protonet\u001b[0m: \u001b[34mhttps://wandb.ai/multi-input/fsl_ssl/runs/vba5sgld\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python wandb_restore.py --id vba5sgld --path ckpts/aircrafts/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/last_model.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit after saving features and testing.\n",
      "checkpoint_dir: ckpts/flowers/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010\n",
      "USE BN: True\n",
      "outfile is features/flowers/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/novel.hdf5\n",
      "0/31\n",
      "10/31\n",
      "20/31\n",
      "30/31\n"
     ]
    }
   ],
   "source": [
    "# Do again with 200 dimensions\n",
    "# Do again with 399.tar\n",
    "\n",
    "!python save_features.py --dataset flowers --train_aug --method protonet --committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing involves fine-tuning. Commit after testing.\n",
      "novel_file features/flowers/_resnet18_protonet_aug_5way_5shot_16query_tracking_lr0.0010/novel.hdf5\n",
      "600 Test Acc = 89.92% +- 0.51%\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataset flowers --train_aug --method protonet --committed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

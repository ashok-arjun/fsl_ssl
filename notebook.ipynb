{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git remote add origin https://github.com/ashok-arjun/fsl_ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/caltech-birds-2011-dataset/CUB_200_2011/images ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master a5e9c89] CUB runs well\n",
      " 7 files changed, 50493 insertions(+), 35 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"CUB runs well\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"write_cross_filelist.py\", line 35, in <module>\n",
      "    fname_number = [ int(re.split('_|\\.', fname)[1]) for fname in fnames]\n",
      "  File \"write_cross_filelist.py\", line 35, in <listcomp>\n",
      "    fname_number = [ int(re.split('_|\\.', fname)[1]) for fname in fnames]\n",
      "ValueError: invalid literal for int() with base 10: 'jpg'\n"
     ]
    }
   ],
   "source": [
    "!python write_cross_filelist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmulti-input\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20210528_114452-11vqc3r9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-frost-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meta-learners/fsl_ssl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meta-learners/fsl_ssl/runs/11vqc3r9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Checkpoint path: checkpoints/dogs/_resnet18_protonet_aug_5way_5shot_16query_lr0.0010\n",
      "Epoch 0 | Batch 10/100 | Loss 25.791528\n",
      "Epoch 0 | Batch 20/100 | Loss 19.452385\n",
      "Epoch 0 | Batch 30/100 | Loss 14.727972\n",
      "Epoch 0 | Batch 40/100 | Loss 11.732775\n",
      "Epoch 0 | Batch 50/100 | Loss 9.849118\n",
      "Epoch 0 | Batch 60/100 | Loss 8.509683\n",
      "Epoch 0 | Batch 70/100 | Loss 7.547474\n",
      "Epoch 0 | Batch 80/100 | Loss 6.819885\n",
      "Epoch 0 | Batch 90/100 | Loss 6.253194\n",
      "Epoch 0 | Batch 100/100 | Loss 5.804753\n",
      "Epoch 1 | Batch 10/100 | Loss 1.633387\n",
      "Epoch 1 | Batch 20/100 | Loss 1.627834\n",
      "Epoch 1 | Batch 30/100 | Loss 1.618748\n",
      "Epoch 1 | Batch 40/100 | Loss 1.616616\n",
      "Epoch 1 | Batch 50/100 | Loss 1.618906\n",
      "Epoch 1 | Batch 60/100 | Loss 1.614242\n",
      "Epoch 1 | Batch 70/100 | Loss 1.608562\n",
      "Epoch 1 | Batch 80/100 | Loss 1.604116\n",
      "Epoch 1 | Batch 90/100 | Loss 1.599851\n",
      "Epoch 1 | Batch 100/100 | Loss 1.597780\n",
      "100 Test Protonet Acc = 31.86% +- 1.39%\n",
      "best model! save...\n",
      "Epoch 2 | Batch 10/100 | Loss 1.575021\n",
      "Epoch 2 | Batch 20/100 | Loss 1.567383\n",
      "Epoch 2 | Batch 30/100 | Loss 1.552098\n",
      "Epoch 2 | Batch 40/100 | Loss 1.568799\n",
      "Epoch 2 | Batch 50/100 | Loss 1.570685\n",
      "Epoch 2 | Batch 60/100 | Loss 1.572118\n",
      "Epoch 2 | Batch 70/100 | Loss 1.569162\n",
      "Epoch 2 | Batch 80/100 | Loss 1.566790\n",
      "Epoch 2 | Batch 90/100 | Loss 1.559168\n",
      "Epoch 2 | Batch 100/100 | Loss 1.557345\n",
      "Epoch 3 | Batch 10/100 | Loss 1.547975\n",
      "Epoch 3 | Batch 20/100 | Loss 1.540721\n",
      "Epoch 3 | Batch 30/100 | Loss 1.530966\n",
      "Epoch 3 | Batch 40/100 | Loss 1.533308\n",
      "Epoch 3 | Batch 50/100 | Loss 1.522217\n",
      "Epoch 3 | Batch 60/100 | Loss 1.526666\n",
      "Epoch 3 | Batch 70/100 | Loss 1.528574\n",
      "Epoch 3 | Batch 80/100 | Loss 1.536364\n",
      "Epoch 3 | Batch 90/100 | Loss 1.534920\n",
      "Epoch 3 | Batch 100/100 | Loss 1.535522\n",
      "Epoch 4 | Batch 10/100 | Loss 1.578154\n",
      "Epoch 4 | Batch 20/100 | Loss 1.545079\n",
      "Epoch 4 | Batch 30/100 | Loss 1.542792\n",
      "Epoch 4 | Batch 40/100 | Loss 1.546010\n",
      "Epoch 4 | Batch 50/100 | Loss 1.544606\n",
      "Epoch 4 | Batch 60/100 | Loss 1.541252\n",
      "Epoch 4 | Batch 70/100 | Loss 1.539610\n",
      "Epoch 4 | Batch 80/100 | Loss 1.537498\n",
      "Epoch 4 | Batch 90/100 | Loss 1.538131\n",
      "Epoch 4 | Batch 100/100 | Loss 1.540447\n",
      "Epoch 5 | Batch 10/100 | Loss 1.497743\n",
      "Epoch 5 | Batch 20/100 | Loss 1.505530\n",
      "Epoch 5 | Batch 30/100 | Loss 1.520096\n",
      "Epoch 5 | Batch 40/100 | Loss 1.525712\n",
      "Epoch 5 | Batch 50/100 | Loss 1.531420\n",
      "Epoch 5 | Batch 60/100 | Loss 1.520396\n",
      "Epoch 5 | Batch 70/100 | Loss 1.517013\n",
      "Epoch 5 | Batch 80/100 | Loss 1.517772\n",
      "Epoch 5 | Batch 90/100 | Loss 1.513263\n",
      "Epoch 5 | Batch 100/100 | Loss 1.515738\n",
      "Epoch 6 | Batch 10/100 | Loss 1.507659\n",
      "Epoch 6 | Batch 20/100 | Loss 1.492420\n",
      "Epoch 6 | Batch 30/100 | Loss 1.499481\n",
      "Epoch 6 | Batch 40/100 | Loss 1.494041\n",
      "Epoch 6 | Batch 50/100 | Loss 1.502083\n",
      "Epoch 6 | Batch 60/100 | Loss 1.498612\n",
      "Epoch 6 | Batch 70/100 | Loss 1.504966\n",
      "Epoch 6 | Batch 80/100 | Loss 1.512334\n",
      "Epoch 6 | Batch 90/100 | Loss 1.514096\n",
      "Epoch 6 | Batch 100/100 | Loss 1.510099\n",
      "Epoch 7 | Batch 10/100 | Loss 1.488111\n",
      "Epoch 7 | Batch 20/100 | Loss 1.497503\n",
      "Epoch 7 | Batch 30/100 | Loss 1.499170\n",
      "Epoch 7 | Batch 40/100 | Loss 1.505004\n",
      "Epoch 7 | Batch 50/100 | Loss 1.508666\n",
      "Epoch 7 | Batch 60/100 | Loss 1.507145\n",
      "Epoch 7 | Batch 70/100 | Loss 1.489543\n",
      "Epoch 7 | Batch 80/100 | Loss 1.493408\n",
      "Epoch 7 | Batch 90/100 | Loss 1.499340\n",
      "Epoch 7 | Batch 100/100 | Loss 1.502155\n",
      "Epoch 8 | Batch 10/100 | Loss 1.534857\n",
      "Epoch 8 | Batch 20/100 | Loss 1.509356\n",
      "Epoch 8 | Batch 30/100 | Loss 1.506723\n",
      "Epoch 8 | Batch 40/100 | Loss 1.506660\n",
      "Epoch 8 | Batch 50/100 | Loss 1.516087\n",
      "Epoch 8 | Batch 60/100 | Loss 1.520471\n",
      "Epoch 8 | Batch 70/100 | Loss 1.512214\n",
      "Epoch 8 | Batch 80/100 | Loss 1.513957\n",
      "Epoch 8 | Batch 90/100 | Loss 1.518285\n",
      "Epoch 8 | Batch 100/100 | Loss 1.516748\n",
      "Epoch 9 | Batch 10/100 | Loss 1.484652\n",
      "Epoch 9 | Batch 20/100 | Loss 1.486748\n",
      "Epoch 9 | Batch 30/100 | Loss 1.483990\n",
      "Epoch 9 | Batch 40/100 | Loss 1.476645\n",
      "Epoch 9 | Batch 50/100 | Loss 1.469632\n",
      "Epoch 9 | Batch 60/100 | Loss 1.471977\n",
      "Epoch 9 | Batch 70/100 | Loss 1.477550\n",
      "Epoch 9 | Batch 80/100 | Loss 1.480375\n",
      "Epoch 9 | Batch 90/100 | Loss 1.475849\n",
      "Epoch 9 | Batch 100/100 | Loss 1.479075\n",
      "Epoch 10 | Batch 10/100 | Loss 1.539978\n",
      "Epoch 10 | Batch 20/100 | Loss 1.540962\n",
      "Epoch 10 | Batch 30/100 | Loss 1.528842\n",
      "Epoch 10 | Batch 40/100 | Loss 1.516423\n",
      "Epoch 10 | Batch 50/100 | Loss 1.503146\n",
      "Epoch 10 | Batch 60/100 | Loss 1.499104\n",
      "Epoch 10 | Batch 70/100 | Loss 1.500521\n",
      "Epoch 10 | Batch 80/100 | Loss 1.492583\n",
      "Epoch 10 | Batch 90/100 | Loss 1.494029\n",
      "Epoch 10 | Batch 100/100 | Loss 1.491591\n",
      "Epoch 11 | Batch 10/100 | Loss 1.450462\n",
      "Epoch 11 | Batch 20/100 | Loss 1.470134\n",
      "Epoch 11 | Batch 30/100 | Loss 1.463275\n",
      "Epoch 11 | Batch 40/100 | Loss 1.470753\n",
      "Epoch 11 | Batch 50/100 | Loss 1.471344\n",
      "Epoch 11 | Batch 60/100 | Loss 1.469526\n",
      "Epoch 11 | Batch 70/100 | Loss 1.474468\n",
      "Epoch 11 | Batch 80/100 | Loss 1.471260\n",
      "Epoch 11 | Batch 90/100 | Loss 1.474303\n",
      "Epoch 11 | Batch 100/100 | Loss 1.472175\n",
      "Epoch 12 | Batch 10/100 | Loss 1.433865\n",
      "Epoch 12 | Batch 20/100 | Loss 1.447335\n",
      "Epoch 12 | Batch 30/100 | Loss 1.461584\n",
      "Epoch 12 | Batch 40/100 | Loss 1.473432\n",
      "Epoch 12 | Batch 50/100 | Loss 1.458897\n",
      "Epoch 12 | Batch 60/100 | Loss 1.462446\n",
      "Epoch 12 | Batch 70/100 | Loss 1.455925\n",
      "Epoch 12 | Batch 80/100 | Loss 1.459140\n",
      "Epoch 12 | Batch 90/100 | Loss 1.458491\n",
      "Epoch 12 | Batch 100/100 | Loss 1.461940\n",
      "Epoch 13 | Batch 10/100 | Loss 1.439113\n",
      "Epoch 13 | Batch 20/100 | Loss 1.436210\n",
      "Epoch 13 | Batch 30/100 | Loss 1.440288\n",
      "Epoch 13 | Batch 40/100 | Loss 1.445081\n",
      "Epoch 13 | Batch 50/100 | Loss 1.457466\n",
      "Epoch 13 | Batch 60/100 | Loss 1.463266\n",
      "Epoch 13 | Batch 70/100 | Loss 1.464089\n",
      "Epoch 13 | Batch 80/100 | Loss 1.460692\n",
      "Epoch 13 | Batch 90/100 | Loss 1.461913\n",
      "Epoch 13 | Batch 100/100 | Loss 1.462854\n",
      "Epoch 14 | Batch 10/100 | Loss 1.414083\n",
      "Epoch 14 | Batch 20/100 | Loss 1.431131\n",
      "Epoch 14 | Batch 30/100 | Loss 1.430727\n",
      "Epoch 14 | Batch 40/100 | Loss 1.440254\n",
      "Epoch 14 | Batch 50/100 | Loss 1.448277\n",
      "Epoch 14 | Batch 60/100 | Loss 1.460440\n",
      "Epoch 14 | Batch 70/100 | Loss 1.470609\n",
      "Epoch 14 | Batch 80/100 | Loss 1.470839\n",
      "Epoch 14 | Batch 90/100 | Loss 1.463023\n",
      "Epoch 14 | Batch 100/100 | Loss 1.461740\n",
      "Epoch 15 | Batch 10/100 | Loss 1.400631\n",
      "Epoch 15 | Batch 20/100 | Loss 1.422630\n",
      "Epoch 15 | Batch 30/100 | Loss 1.414931\n",
      "Epoch 15 | Batch 40/100 | Loss 1.426275\n",
      "Epoch 15 | Batch 50/100 | Loss 1.441202\n",
      "Epoch 15 | Batch 60/100 | Loss 1.451165\n",
      "Epoch 15 | Batch 70/100 | Loss 1.456013\n",
      "Epoch 15 | Batch 80/100 | Loss 1.456951\n",
      "Epoch 15 | Batch 90/100 | Loss 1.452955\n",
      "Epoch 15 | Batch 100/100 | Loss 1.453272\n",
      "Epoch 16 | Batch 10/100 | Loss 1.421308\n",
      "Epoch 16 | Batch 20/100 | Loss 1.436113\n",
      "Epoch 16 | Batch 30/100 | Loss 1.430125\n",
      "Epoch 16 | Batch 40/100 | Loss 1.442913\n",
      "Epoch 16 | Batch 50/100 | Loss 1.444910\n",
      "Epoch 16 | Batch 60/100 | Loss 1.448394\n",
      "Epoch 16 | Batch 70/100 | Loss 1.450942\n",
      "Epoch 16 | Batch 80/100 | Loss 1.453350\n",
      "Epoch 16 | Batch 90/100 | Loss 1.448925\n",
      "Epoch 16 | Batch 100/100 | Loss 1.451099\n",
      "Epoch 17 | Batch 10/100 | Loss 1.489285\n",
      "Epoch 17 | Batch 20/100 | Loss 1.470273\n",
      "Epoch 17 | Batch 30/100 | Loss 1.446472\n",
      "Epoch 17 | Batch 40/100 | Loss 1.444962\n",
      "Epoch 17 | Batch 50/100 | Loss 1.450728\n",
      "Epoch 17 | Batch 60/100 | Loss 1.450914\n",
      "Epoch 17 | Batch 70/100 | Loss 1.460460\n",
      "Epoch 17 | Batch 80/100 | Loss 1.459607\n",
      "Epoch 17 | Batch 90/100 | Loss 1.460178\n",
      "Epoch 17 | Batch 100/100 | Loss 1.453701\n",
      "Epoch 18 | Batch 10/100 | Loss 1.452219\n",
      "Epoch 18 | Batch 20/100 | Loss 1.465299\n",
      "Epoch 18 | Batch 30/100 | Loss 1.459950\n",
      "Epoch 18 | Batch 40/100 | Loss 1.455915\n",
      "Epoch 18 | Batch 50/100 | Loss 1.441269\n",
      "Epoch 18 | Batch 60/100 | Loss 1.426595\n",
      "Epoch 18 | Batch 70/100 | Loss 1.427563\n",
      "Epoch 18 | Batch 80/100 | Loss 1.432822\n",
      "Epoch 18 | Batch 90/100 | Loss 1.427668\n",
      "Epoch 18 | Batch 100/100 | Loss 1.427602\n",
      "Epoch 19 | Batch 10/100 | Loss 1.420813\n",
      "Epoch 19 | Batch 20/100 | Loss 1.423796\n",
      "Epoch 19 | Batch 30/100 | Loss 1.414845\n",
      "Epoch 19 | Batch 40/100 | Loss 1.421181\n",
      "Epoch 19 | Batch 50/100 | Loss 1.432290\n",
      "Epoch 19 | Batch 60/100 | Loss 1.423574\n",
      "Epoch 19 | Batch 70/100 | Loss 1.422179\n",
      "Epoch 19 | Batch 80/100 | Loss 1.434397\n",
      "Epoch 19 | Batch 90/100 | Loss 1.433154\n",
      "Epoch 19 | Batch 100/100 | Loss 1.435955\n",
      "Epoch 20 | Batch 10/100 | Loss 1.480549\n",
      "Epoch 20 | Batch 20/100 | Loss 1.444739\n",
      "Epoch 20 | Batch 30/100 | Loss 1.424687\n",
      "Epoch 20 | Batch 40/100 | Loss 1.409104\n",
      "Epoch 20 | Batch 50/100 | Loss 1.410150\n",
      "Epoch 20 | Batch 60/100 | Loss 1.419061\n",
      "Epoch 20 | Batch 70/100 | Loss 1.418497\n",
      "Epoch 20 | Batch 80/100 | Loss 1.418372\n",
      "Epoch 20 | Batch 90/100 | Loss 1.423423\n",
      "Epoch 20 | Batch 100/100 | Loss 1.426544\n",
      "Epoch 21 | Batch 10/100 | Loss 1.419112\n",
      "Epoch 21 | Batch 20/100 | Loss 1.417708\n",
      "Epoch 21 | Batch 30/100 | Loss 1.395589\n",
      "Epoch 21 | Batch 40/100 | Loss 1.408145\n",
      "Epoch 21 | Batch 50/100 | Loss 1.419822\n",
      "Epoch 21 | Batch 60/100 | Loss 1.423027\n",
      "Epoch 21 | Batch 70/100 | Loss 1.422851\n",
      "Epoch 21 | Batch 80/100 | Loss 1.416162\n",
      "Epoch 21 | Batch 90/100 | Loss 1.411295\n",
      "Epoch 21 | Batch 100/100 | Loss 1.415593\n",
      "100 Test Protonet Acc = 42.20% +- 1.69%\n",
      "best model! save...\n",
      "Epoch 22 | Batch 10/100 | Loss 1.432596\n",
      "Epoch 22 | Batch 20/100 | Loss 1.407944\n",
      "Epoch 22 | Batch 30/100 | Loss 1.393763\n",
      "Epoch 22 | Batch 40/100 | Loss 1.408884\n",
      "Epoch 22 | Batch 50/100 | Loss 1.425152\n",
      "Epoch 22 | Batch 60/100 | Loss 1.427446\n",
      "Epoch 22 | Batch 70/100 | Loss 1.430844\n",
      "Epoch 22 | Batch 80/100 | Loss 1.428048\n",
      "Epoch 22 | Batch 90/100 | Loss 1.419741\n",
      "Epoch 22 | Batch 100/100 | Loss 1.411128\n",
      "Epoch 23 | Batch 10/100 | Loss 1.452832\n",
      "Epoch 23 | Batch 20/100 | Loss 1.428640\n",
      "Epoch 23 | Batch 30/100 | Loss 1.426040\n",
      "Epoch 23 | Batch 40/100 | Loss 1.439206\n",
      "Epoch 23 | Batch 50/100 | Loss 1.440982\n",
      "Epoch 23 | Batch 60/100 | Loss 1.436368\n",
      "Epoch 23 | Batch 70/100 | Loss 1.435532\n",
      "Epoch 23 | Batch 80/100 | Loss 1.430777\n",
      "Epoch 23 | Batch 90/100 | Loss 1.429076\n",
      "Epoch 23 | Batch 100/100 | Loss 1.434260\n",
      "Epoch 24 | Batch 10/100 | Loss 1.417998\n",
      "Epoch 24 | Batch 20/100 | Loss 1.418821\n",
      "Epoch 24 | Batch 30/100 | Loss 1.416624\n",
      "Epoch 24 | Batch 40/100 | Loss 1.400447\n",
      "Epoch 24 | Batch 50/100 | Loss 1.395422\n",
      "Epoch 24 | Batch 60/100 | Loss 1.405592\n",
      "Epoch 24 | Batch 70/100 | Loss 1.402077\n",
      "Epoch 24 | Batch 80/100 | Loss 1.403644\n",
      "Epoch 24 | Batch 90/100 | Loss 1.402303\n",
      "Epoch 24 | Batch 100/100 | Loss 1.400016\n",
      "Epoch 25 | Batch 10/100 | Loss 1.364785\n",
      "Epoch 25 | Batch 20/100 | Loss 1.356797\n",
      "Epoch 25 | Batch 30/100 | Loss 1.374119\n",
      "Epoch 25 | Batch 40/100 | Loss 1.372207\n",
      "Epoch 25 | Batch 50/100 | Loss 1.379457\n",
      "Epoch 25 | Batch 60/100 | Loss 1.390860\n",
      "Epoch 25 | Batch 70/100 | Loss 1.392120\n",
      "Epoch 25 | Batch 80/100 | Loss 1.387565\n",
      "Epoch 25 | Batch 90/100 | Loss 1.383731\n",
      "Epoch 25 | Batch 100/100 | Loss 1.382597\n",
      "Epoch 26 | Batch 10/100 | Loss 1.405229\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset dogs --train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.tar  configs.json  events.out.tfevents.1622195914.538eba3681d4\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
